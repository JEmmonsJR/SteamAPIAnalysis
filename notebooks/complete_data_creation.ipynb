{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook uses code based on code written by Nik Davis. This code will gather data from the Steam Store API using python. Please check out his amazing blog post! https://nik-davis.github.io/posts/2019/steam-data-collection/\n",
    "\n",
    "Their version was greatly out dated, so I also use a modified version of Nik's code that was written by Duerkos. https://github.com/Duerkos/steam_analysis/tree/main\n",
    "\n",
    "That two was also a little outdated, so I added slight modifications to the code in order for it to run in more modern python.\n",
    "\n",
    "This entire notebook is separated into three smaller notebooks for easier consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import csv\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import SSLError\n",
    "\n",
    "# customisations - ensure tables show all columns\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(url,parameters=None, steamspy=False):\n",
    "    \"\"\"Return json-formatted response of a get request using optional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "    parameters : {'parameter': 'value'}\n",
    "        parameters to pass as part of get request\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    json_data\n",
    "        json-formatted response (dict-like)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url=url, params=parameters)\n",
    "    except SSLError as s:\n",
    "        print('SSL Error:', s)\n",
    "        \n",
    "        for i in range(5, 0, -1):\n",
    "            print('\\rWaiting... ({})'.format(i), end='')\n",
    "            time.sleep(1)\n",
    "        print('\\rRetrying.' + ' '*10)\n",
    "        \n",
    "        # recursively try again\n",
    "        return get_request(url, parameters, steamspy)\n",
    "    \n",
    "    if response:\n",
    "        try:\n",
    "            return response.json()\n",
    "        except:\n",
    "            False\n",
    "    else:\n",
    "        # We do not know how many pages steamspy has... and it seems to work well, so we will use no response to stop.\n",
    "        if steamspy:\n",
    "            return \"stop\"\n",
    "        else :\n",
    "            # response is none usually means too many requests. Wait and try again \n",
    "            print('No response, waiting 10 seconds...')\n",
    "            time.sleep(10)\n",
    "            print('Retrying.')\n",
    "            return get_request(url, parameters, steamspy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_data(app_list, start, stop, parser, pause):\n",
    "    \"\"\"Return list of app data generated from parser.\n",
    "    \n",
    "    parser : function to handle request\n",
    "    \"\"\"\n",
    "    app_data = []\n",
    "    \n",
    "    # iterate through each row of app_list, confined by start and stop\n",
    "    for index, appid in app_list[start:stop].items():\n",
    "        print('Current index: {}'.format(index), end='\\r')\n",
    "\n",
    "        # retrive app data for a row, handled by supplied parser, and append to list\n",
    "        try:\n",
    "            data = parser(appid)\n",
    "            app_data.append(data)\n",
    "        except:\n",
    "            print(\"Error with \"+str(appid))\n",
    "        time.sleep(pause) # prevent overloading api with requests\n",
    "    \n",
    "    return app_data\n",
    "\n",
    "\n",
    "def process_batches(parser, app_list, download_path, data_filename, index_filename,\n",
    "                    columns, begin=0, end=-1, batchsize=100, pause=1):\n",
    "    \"\"\"Process app data in batches, writing directly to file.\n",
    "    \n",
    "    parser : custom function to format request\n",
    "    app_list : dataframe of appid and name\n",
    "    download_path : path to store data\n",
    "    data_filename : filename to save app data\n",
    "    index_filename : filename to store highest index written\n",
    "    columns : column names for file\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    begin : starting index (get from index_filename, default 0)\n",
    "    end : index to finish (defaults to end of app_list)\n",
    "    batchsize : number of apps to write in each batch (default 100)\n",
    "    pause : time to wait after each api request (defualt 1)\n",
    "    \n",
    "    returns: none\n",
    "    \"\"\"\n",
    "    print('Starting at index {}:\\n'.format(begin))\n",
    "    \n",
    "    # by default, process all apps in app_list\n",
    "    if end == -1:\n",
    "        end = len(app_list) + 1\n",
    "    \n",
    "    # generate array of batch begin and end points\n",
    "    batches = np.arange(begin, end, batchsize)\n",
    "    batches = np.append(batches, end)\n",
    "    \n",
    "    apps_written = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    for i in range(len(batches) - 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = batches[i]\n",
    "        stop = batches[i+1]\n",
    "        \n",
    "        app_data = get_app_data(app_list, start, stop, parser, pause)\n",
    "        \n",
    "        rel_path = os.path.join(download_path, data_filename)\n",
    "        \n",
    "        # writing app data to file\n",
    "        with open(rel_path, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns, extrasaction='ignore')\n",
    "            \n",
    "            for j in range(3,0,-1):\n",
    "                print(\"\\rAbout to write data, don't stop script! ({})\".format(j), end='')\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            writer.writerows(app_data)\n",
    "            print('\\rExported lines {}-{} to {}.'.format(start, stop-1, data_filename), end=' ')\n",
    "            \n",
    "        apps_written += len(app_data)\n",
    "        \n",
    "        idx_path = os.path.join(download_path, index_filename)\n",
    "        \n",
    "        # writing last index to file\n",
    "        with open(idx_path, 'w') as f:\n",
    "            index = stop\n",
    "            print(index, file=f)\n",
    "            \n",
    "        # logging time taken\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        \n",
    "        batch_times.append(time_taken)\n",
    "        mean_time = statistics.mean(batch_times)\n",
    "        \n",
    "        est_remaining = (len(batches) - i - 2) * mean_time\n",
    "        \n",
    "        remaining_td = dt.timedelta(seconds=round(est_remaining))\n",
    "        time_td = dt.timedelta(seconds=round(time_taken))\n",
    "        mean_td = dt.timedelta(seconds=round(mean_time))\n",
    "        \n",
    "        print('Batch {} time: {} (avg: {}, remaining: {})'.format(i, time_td, mean_td, remaining_td))\n",
    "            \n",
    "    print('\\nProcessing batches complete. {} apps written'.format(apps_written))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index(download_path, index_filename):\n",
    "    \"\"\"Reset index in file to 0.\"\"\"\n",
    "    rel_path = os.path.join(download_path, index_filename)\n",
    "    \n",
    "    f= open(rel_path, 'w')\n",
    "    f.write(\"0\")\n",
    "        \n",
    "\n",
    "def get_index(download_path, index_filename):\n",
    "    \"\"\"Retrieve index from file, returning 0 if file not found.\"\"\"\n",
    "    try:\n",
    "        rel_path = os.path.join(download_path, index_filename)\n",
    "\n",
    "        with open(rel_path, 'r') as f:\n",
    "            index = int(f.readline())\n",
    "            #This just reads the initial line\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        index = 0\n",
    "        \n",
    "    return index\n",
    "\n",
    "\n",
    "def prepare_data_file(download_path, filename, index, columns):\n",
    "    \"\"\"Create file and write headers if index is 0.\"\"\"\n",
    "    if index == 0:\n",
    "        rel_path = os.path.join(download_path, filename)\n",
    "\n",
    "        with open(rel_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            writer.writeheader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Steam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAppListBatch(url, parameters):\n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    steam_id = pd.DataFrame.from_dict(json_data[\"response\"][\"apps\"])\n",
    "    try:\n",
    "        more_results = json_data[\"response\"][\"have_more_results\"]\n",
    "        last_appid =  json_data[\"response\"][\"last_appid\"]\n",
    "    except:\n",
    "        more_results = False\n",
    "        last_appid = False\n",
    "    return more_results, steam_id, last_appid\n",
    "\n",
    "def get_update_ids_old(updatedlist, oldlist):\n",
    "    updatedlist['key1'] = 1\n",
    "    oldlist['key2'] = 1\n",
    "    updatedlist = pd.merge(updatedlist, oldlist, right_on=['steam_appid','name'],left_on=['appid','name'], how = 'outer')\n",
    "    updatedlist = updatedlist[~(updatedlist.key2 == updatedlist.key1)]\n",
    "    updatedlist = updatedlist.drop(['key1','key2','steam_appid'], axis=1)\n",
    "    return updatedlist\n",
    "\n",
    "def get_update_ids(idList, oldFullList):\n",
    "    #We are going to forget about names and only care about IDs.\n",
    "    idList = idList[\"appid\"]\n",
    "    oldFullList = oldFullList[\"steam_appid\"]\n",
    "    oldFullList.columns = [\"appid\"]\n",
    "    updatedList = pd.concat([idList, oldFullList])\n",
    "    updatedList = updatedList.drop_duplicates(keep=False)\n",
    "    updatedList = updatedList.reset_index(drop=True)\n",
    "    return updatedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAppList():\n",
    "    with open('../data/steam_key.txt') as f:\n",
    "        key = f.read()\n",
    "\n",
    "    url = \"https://api.steampowered.com/IStoreService/GetAppList/v1/?\"\n",
    "    parameters = {\"key\": key}\n",
    "    more_results = True\n",
    "    begin = True\n",
    "    # from the request we get the more_results flag and also the last_appid, so we use them for the next requests.\n",
    "    while (more_results):\n",
    "        more_results, steam_ids, last_appid = getAppListBatch(url, parameters)\n",
    "        parameters[\"last_appid\"] = last_appid\n",
    "        if (begin):\n",
    "            steam_allids = steam_ids\n",
    "            begin = False\n",
    "        else:\n",
    "            steam_allids = pd.concat([steam_allids, steam_ids])\n",
    "    return steam_allids\n",
    "# request 'all' from steam spy and parse into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_steam_request(appid):\n",
    "    \"\"\"Unique parser to handle data from Steam Store API.\n",
    "    \n",
    "    Returns : json formatted data (dict-like)\n",
    "    \"\"\"\n",
    "    with open('../data/steam_key.txt') as f:\n",
    "        key = f.read()\n",
    "        \n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": appid, \"key\": key}\n",
    "    \n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    json_app_data = json_data[str(appid)]\n",
    "    \n",
    "    if json_app_data['success']:\n",
    "        data = json_app_data['data']\n",
    "    else:\n",
    "        data = {'steam_appid': appid}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "# Set file parameters\n",
    "download_path = '../data/download/'\n",
    "steam_app_data = 'steam_app_data.csv'\n",
    "steam_app_data_delta = 'steam_app_data_delta.csv'\n",
    "steam_index = 'steam_index.txt'\n",
    "\n",
    "steam_columns = [\n",
    "    'type', 'name', 'steam_appid', 'required_age', 'is_free', 'controller_support',\n",
    "    'dlc', 'detailed_description', 'about_the_game', 'short_description', 'fullgame',\n",
    "    'supported_languages', 'header_image', 'website', 'pc_requirements', 'mac_requirements',\n",
    "    'linux_requirements', 'legal_notice', 'drm_notice', 'ext_user_account_notice',\n",
    "    'developers', 'publishers', 'demos', 'price_overview', 'packages', 'package_groups',\n",
    "    'platforms', 'metacritic', 'reviews', 'categories', 'genres', 'screenshots',\n",
    "    'movies', 'recommendations', 'achievements', 'release_date', 'support_info',\n",
    "    'background', 'content_descriptors'\n",
    "]\n",
    "\n",
    "# Overwrites last index for demonstration (would usually store highest index so can continue across sessions)\n",
    "if (os.path.isfile(download_path+steam_app_data_delta) == False):\n",
    "    reset_index(download_path, steam_index)\n",
    "\n",
    "# Retrieve last index downloaded from file\n",
    "index = get_index(download_path, steam_index)\n",
    "\n",
    "# Wipe or create data file and write headers if no previous  data\n",
    "if (os.path.isfile(download_path+steam_app_data) == False):\n",
    "    prepare_data_file(download_path, steam_app_data, index, steam_columns)\n",
    "    \n",
    "# Wipe or create data file delta and write headers if index is 0\n",
    "if (os.path.isfile(download_path+steam_app_data_delta) == False):\n",
    "    prepare_data_file(download_path, steam_app_data_delta, index, steam_columns)\n",
    "    \n",
    "    \n",
    "# Here we get the list of appids from steam\n",
    "full_steam_ids = getAppList()\n",
    "\n",
    "# Here we get the real list of ids not yet in our dataframe. If this is the first time we are downloading the data, we can skip\n",
    "# This step and instead use the full app_list.\n",
    "try:\n",
    "    oldlist = pd.read_csv('../data/download/steam_app_data.csv', usecols = ['name','steam_appid'])\n",
    "    steam_ids = get_update_ids(full_steam_ids, oldlist)\n",
    "except FileNotFoundError:\n",
    "    print(\"Pre-existing file not found. First time downloading full app data from steam. This will take a while.\\n\")\n",
    "    steam_ids = full_steam_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New IDs detected: 1143\n"
     ]
    }
   ],
   "source": [
    "print(\"New IDs detected: \"+str(len(steam_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I separated the long process to be able to debug it better.\n",
    "# Set end and chunksize for demonstration - remove to run through entire app list\n",
    "# Here by default we passed \"app_list\" that contained all the information and saved it, now we will modify it a bit\n",
    "# And add pre-processing and post-processing\n",
    "print(\"Adding \"+str(len(steam_ids))+\" new ids.\\n\")\n",
    "process_batches(\n",
    "    parser=parse_steam_request,\n",
    "    app_list=steam_ids,\n",
    "    download_path=download_path,\n",
    "    data_filename=steam_app_data_delta,\n",
    "    index_filename=steam_index,\n",
    "    columns=steam_columns,\n",
    "    begin=index,\n",
    "    #end=10,\n",
    "    #batchsize=5\n",
    ")\n",
    "\n",
    "try:\n",
    "    oldlist = pd.read_csv('../data/download/steam_app_data.csv')\n",
    "    # We change the old file to backup, so remove any backup named this way before...\n",
    "    os.rename('../data/download/steam_app_data.csv', '../data/download/steam_app_data_backup.csv')\n",
    "    newlist = pd.read_csv('../data/download/steam_app_data_delta.csv')\n",
    "    oldlist = oldlist.append(newlist, ignore_index=True)\n",
    "    oldlist.to_csv('../data/download/steam_app_data.csv', index=False)\n",
    "except FileNotFoundError:\n",
    "    os.rename('../data/download/steam_app_data_delta.csv', '../data/download/steam_app_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('../data/download/steam_app_data_delta.csv', '../data/download/steam_app_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Data for Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jdejr\\AppData\\Local\\Temp\\ipykernel_26804\\3041477814.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  steam_app_data = pd.read_csv('../data/download/steam_app_data.csv')\n"
     ]
    }
   ],
   "source": [
    "steam_app_data = pd.read_csv('../data/download/steam_app_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_app_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_app_data[steam_app_data.duplicated(subset=\"steam_appid\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_app_data[steam_app_data[\"steam_appid\"] == 34330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(steam_app_data)-len(full_steam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ids = get_update_ids(full_steam_ids, steam_app_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diff_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 135 new items added to steam since initially running this on 2/6/2024. Ran the second time on 2/8/2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting rid of dups I will only focus on the apps with names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_app_data = steam_app_data[~steam_app_data[\"name\"].isna()]\n",
    "steam_app_data = steam_app_data.drop_duplicates(subset=\"steam_appid\", keep=\"last\")\n",
    "steam_app_data.to_csv(\"../data/download/steam_app_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect downloaded data\n",
    "steam_app_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_app_data[steam_app_data.duplicated(subset=\"steam_appid\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_steam_ids.duplicated(subset=\"appid\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>price_change_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>1666823513</td>\n",
       "      <td>21760363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "      <td>1579634708</td>\n",
       "      <td>21760363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>1512413490</td>\n",
       "      <td>21319050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>1568752159</td>\n",
       "      <td>21760363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>1579628243</td>\n",
       "      <td>21760363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9218</th>\n",
       "      <td>2845120</td>\n",
       "      <td>Exoracer</td>\n",
       "      <td>1708450746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9219</th>\n",
       "      <td>2845400</td>\n",
       "      <td>Hidden Cats In Breeze Village</td>\n",
       "      <td>1708397843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9220</th>\n",
       "      <td>2845790</td>\n",
       "      <td>Life as a Lich</td>\n",
       "      <td>1708450623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221</th>\n",
       "      <td>2846340</td>\n",
       "      <td>Color Splash: Predators</td>\n",
       "      <td>1708467377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>2846740</td>\n",
       "      <td>SEARCH ALL - DOGS</td>\n",
       "      <td>1708462247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99223 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        appid                           name  last_modified  \\\n",
       "0          10                 Counter-Strike     1666823513   \n",
       "1          20          Team Fortress Classic     1579634708   \n",
       "2          30                  Day of Defeat     1512413490   \n",
       "3          40             Deathmatch Classic     1568752159   \n",
       "4          50      Half-Life: Opposing Force     1579628243   \n",
       "...       ...                            ...            ...   \n",
       "9218  2845120                       Exoracer     1708450746   \n",
       "9219  2845400  Hidden Cats In Breeze Village     1708397843   \n",
       "9220  2845790                 Life as a Lich     1708450623   \n",
       "9221  2846340        Color Splash: Predators     1708467377   \n",
       "9222  2846740              SEARCH ALL - DOGS     1708462247   \n",
       "\n",
       "      price_change_number  \n",
       "0                21760363  \n",
       "1                21760363  \n",
       "2                21319050  \n",
       "3                21760363  \n",
       "4                21760363  \n",
       "...                   ...  \n",
       "9218                    0  \n",
       "9219                    0  \n",
       "9220                    0  \n",
       "9221                    0  \n",
       "9222                    0  \n",
       "\n",
       "[99223 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_steam_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steam Spy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index 54300:\n",
      "\n",
      "Exported lines 54300-54599 to steamspy_data.csv. Batch 0 time: 0:02:32 (avg: 0:02:32, remaining: 6:16:15)\n",
      "Exported lines 54600-54899 to steamspy_data.csv. Batch 1 time: 0:02:33 (avg: 0:02:32, remaining: 6:15:16)\n",
      "Exported lines 54900-55199 to steamspy_data.csv. Batch 2 time: 0:02:32 (avg: 0:02:32, remaining: 6:12:40)\n",
      "Exported lines 55200-55499 to steamspy_data.csv. Batch 3 time: 0:02:33 (avg: 0:02:32, remaining: 6:10:54)\n",
      "Exported lines 55500-55799 to steamspy_data.csv. Batch 4 time: 0:02:32 (avg: 0:02:32, remaining: 6:08:13)\n",
      "Exported lines 55800-56099 to steamspy_data.csv. Batch 5 time: 0:02:33 (avg: 0:02:32, remaining: 6:05:49)\n",
      "Exported lines 56100-56399 to steamspy_data.csv. Batch 6 time: 0:02:33 (avg: 0:02:33, remaining: 6:03:31)\n",
      "Exported lines 56400-56699 to steamspy_data.csv. Batch 7 time: 0:02:34 (avg: 0:02:33, remaining: 6:01:25)\n",
      "Exported lines 56700-56999 to steamspy_data.csv. Batch 8 time: 0:02:32 (avg: 0:02:33, remaining: 5:58:48)\n",
      "Exported lines 57000-57299 to steamspy_data.csv. Batch 9 time: 0:02:34 (avg: 0:02:33, remaining: 5:56:31)\n",
      "Exported lines 57300-57599 to steamspy_data.csv. Batch 10 time: 0:02:31 (avg: 0:02:33, remaining: 5:53:31)\n",
      "Exported lines 57600-57899 to steamspy_data.csv. Batch 11 time: 0:02:32 (avg: 0:02:33, remaining: 5:50:49)\n",
      "Exported lines 57900-58199 to steamspy_data.csv. Batch 12 time: 0:02:30 (avg: 0:02:32, remaining: 5:47:47)\n",
      "Exported lines 58200-58499 to steamspy_data.csv. Batch 13 time: 0:02:31 (avg: 0:02:32, remaining: 5:45:03)\n",
      "Exported lines 58500-58799 to steamspy_data.csv. Batch 14 time: 0:02:30 (avg: 0:02:32, remaining: 5:42:11)\n",
      "Exported lines 58800-59099 to steamspy_data.csv. Batch 15 time: 0:02:31 (avg: 0:02:32, remaining: 5:39:31)\n",
      "Exported lines 59100-59399 to steamspy_data.csv. Batch 16 time: 0:02:29 (avg: 0:02:32, remaining: 5:36:39)\n",
      "Exported lines 59400-59699 to steamspy_data.csv. Batch 17 time: 0:02:30 (avg: 0:02:32, remaining: 5:33:50)\n",
      "Exported lines 59700-59999 to steamspy_data.csv. Batch 18 time: 0:02:29 (avg: 0:02:32, remaining: 5:31:01)\n",
      "Exported lines 60000-60299 to steamspy_data.csv. Batch 19 time: 0:02:29 (avg: 0:02:32, remaining: 5:28:15)\n",
      "Exported lines 60300-60599 to steamspy_data.csv. Batch 20 time: 0:02:31 (avg: 0:02:31, remaining: 5:25:40)\n",
      "Exported lines 60600-60899 to steamspy_data.csv. Batch 21 time: 0:02:34 (avg: 0:02:32, remaining: 5:23:26)\n",
      "Exported lines 60900-61199 to steamspy_data.csv. Batch 22 time: 0:02:32 (avg: 0:02:32, remaining: 5:20:55)\n",
      "Exported lines 61200-61499 to steamspy_data.csv. Batch 23 time: 0:02:35 (avg: 0:02:32, remaining: 5:18:40)\n",
      "Exported lines 61500-61799 to steamspy_data.csv. Batch 24 time: 0:02:34 (avg: 0:02:32, remaining: 5:16:20)\n",
      "Exported lines 61800-62099 to steamspy_data.csv. Batch 25 time: 0:02:33 (avg: 0:02:32, remaining: 5:13:55)\n",
      "Exported lines 62100-62399 to steamspy_data.csv. Batch 26 time: 0:02:33 (avg: 0:02:32, remaining: 5:11:26)\n",
      "Exported lines 62400-62699 to steamspy_data.csv. Batch 27 time: 0:02:34 (avg: 0:02:32, remaining: 5:09:05)\n",
      "Exported lines 62700-62999 to steamspy_data.csv. Batch 28 time: 0:02:29 (avg: 0:02:32, remaining: 5:06:23)\n",
      "Exported lines 63000-63299 to steamspy_data.csv. Batch 29 time: 0:02:30 (avg: 0:02:32, remaining: 5:03:43)\n",
      "Exported lines 63300-63599 to steamspy_data.csv. Batch 30 time: 0:02:32 (avg: 0:02:32, remaining: 5:01:11)\n",
      "Exported lines 63600-63899 to steamspy_data.csv. Batch 31 time: 0:02:30 (avg: 0:02:32, remaining: 4:58:31)\n",
      "Exported lines 63900-64199 to steamspy_data.csv. Batch 32 time: 0:02:28 (avg: 0:02:32, remaining: 4:55:46)\n",
      "Exported lines 64200-64499 to steamspy_data.csv. Batch 33 time: 0:02:29 (avg: 0:02:32, remaining: 4:53:06)\n",
      "Exported lines 64500-64799 to steamspy_data.csv. Batch 34 time: 0:02:30 (avg: 0:02:32, remaining: 4:50:29)\n",
      "Exported lines 64800-65099 to steamspy_data.csv. Batch 35 time: 0:02:28 (avg: 0:02:31, remaining: 4:47:48)\n",
      "Exported lines 65100-65399 to steamspy_data.csv. Batch 36 time: 0:02:30 (avg: 0:02:31, remaining: 4:45:13)\n",
      "Exported lines 65400-65699 to steamspy_data.csv. Batch 37 time: 0:02:31 (avg: 0:02:31, remaining: 4:42:40)\n",
      "Exported lines 65700-65999 to steamspy_data.csv. Batch 38 time: 0:02:30 (avg: 0:02:31, remaining: 4:40:04)\n",
      "Exported lines 66000-66299 to steamspy_data.csv. Batch 39 time: 0:02:30 (avg: 0:02:31, remaining: 4:37:30)\n",
      "Exported lines 66300-66599 to steamspy_data.csv. Batch 40 time: 0:02:52 (avg: 0:02:32, remaining: 4:35:54)\n",
      "Exported lines 66600-66899 to steamspy_data.csv. Batch 41 time: 0:02:30 (avg: 0:02:32, remaining: 4:33:17)\n",
      "Exported lines 66900-67199 to steamspy_data.csv. Batch 42 time: 0:02:30 (avg: 0:02:32, remaining: 4:30:41)\n",
      "Exported lines 67200-67499 to steamspy_data.csv. Batch 43 time: 0:02:51 (avg: 0:02:32, remaining: 4:28:55)\n",
      "Exported lines 67500-67799 to steamspy_data.csv. Batch 44 time: 0:02:31 (avg: 0:02:32, remaining: 4:26:19)\n",
      "Error with 19551607\n",
      "Error with 19551708\n",
      "Error with 19552009\n",
      "Exported lines 67800-68099 to steamspy_data.csv. Batch 45 time: 0:03:54 (avg: 0:02:34, remaining: 4:26:53)\n",
      "Exported lines 68100-68399 to steamspy_data.csv. Batch 46 time: 0:02:32 (avg: 0:02:34, remaining: 4:24:15)\n",
      "Exported lines 68400-68699 to steamspy_data.csv. Batch 47 time: 0:02:31 (avg: 0:02:34, remaining: 4:21:35)\n",
      "Exported lines 68700-68999 to steamspy_data.csv. Batch 48 time: 0:02:30 (avg: 0:02:34, remaining: 4:18:52)\n",
      "Exported lines 69000-69299 to steamspy_data.csv. Batch 49 time: 0:02:31 (avg: 0:02:34, remaining: 4:16:13)\n",
      "Exported lines 69300-69599 to steamspy_data.csv. Batch 50 time: 0:02:31 (avg: 0:02:34, remaining: 4:13:34)\n",
      "Exported lines 69600-69899 to steamspy_data.csv. Batch 51 time: 0:02:29 (avg: 0:02:34, remaining: 4:10:52)\n",
      "Exported lines 69900-70199 to steamspy_data.csv. Batch 52 time: 0:02:30 (avg: 0:02:34, remaining: 4:08:12)\n",
      "Exported lines 70200-70499 to steamspy_data.csv. Batch 53 time: 0:02:29 (avg: 0:02:33, remaining: 4:05:30)\n",
      "Exported lines 70500-70799 to steamspy_data.csv. Batch 54 time: 0:02:30 (avg: 0:02:33, remaining: 4:02:51)\n",
      "Exported lines 70800-71099 to steamspy_data.csv. Batch 55 time: 0:02:30 (avg: 0:02:33, remaining: 4:00:11)\n",
      "Exported lines 71100-71399 to steamspy_data.csv. Batch 56 time: 0:02:29 (avg: 0:02:33, remaining: 3:57:31)\n",
      "Exported lines 71400-71699 to steamspy_data.csv. Batch 57 time: 0:02:29 (avg: 0:02:33, remaining: 3:54:51)\n",
      "Exported lines 71700-71999 to steamspy_data.csv. Batch 58 time: 0:02:29 (avg: 0:02:33, remaining: 3:52:11)\n",
      "Exported lines 72000-72299 to steamspy_data.csv. Batch 59 time: 0:02:31 (avg: 0:02:33, remaining: 3:49:35)\n",
      "Exported lines 72300-72599 to steamspy_data.csv. Batch 60 time: 0:02:31 (avg: 0:02:33, remaining: 3:47:00)\n",
      "Exported lines 72600-72899 to steamspy_data.csv. Batch 61 time: 0:02:30 (avg: 0:02:33, remaining: 3:44:22)\n",
      "Exported lines 72900-73199 to steamspy_data.csv. Batch 62 time: 0:02:30 (avg: 0:02:33, remaining: 3:41:44)\n",
      "Exported lines 73200-73499 to steamspy_data.csv. Batch 63 time: 0:02:31 (avg: 0:02:33, remaining: 3:39:08)\n",
      "Exported lines 73500-73799 to steamspy_data.csv. Batch 64 time: 0:02:30 (avg: 0:02:33, remaining: 3:36:31)\n",
      "Exported lines 73800-74099 to steamspy_data.csv. Batch 65 time: 0:02:28 (avg: 0:02:33, remaining: 3:33:53)\n",
      "Exported lines 74100-74399 to steamspy_data.csv. Batch 66 time: 0:02:29 (avg: 0:02:33, remaining: 3:31:15)\n",
      "Exported lines 74400-74699 to steamspy_data.csv. Batch 67 time: 0:02:29 (avg: 0:02:33, remaining: 3:28:37)\n",
      "Exported lines 74700-74999 to steamspy_data.csv. Batch 68 time: 0:02:28 (avg: 0:02:33, remaining: 3:25:59)\n",
      "Exported lines 75000-75299 to steamspy_data.csv. Batch 69 time: 0:02:28 (avg: 0:02:33, remaining: 3:23:22)\n",
      "Exported lines 75300-75599 to steamspy_data.csv. Batch 70 time: 0:02:33 (avg: 0:02:33, remaining: 3:20:50)\n",
      "Exported lines 75600-75899 to steamspy_data.csv. Batch 71 time: 0:02:33 (avg: 0:02:33, remaining: 3:18:17)\n",
      "Exported lines 75900-76199 to steamspy_data.csv. Batch 72 time: 0:02:30 (avg: 0:02:32, remaining: 3:15:42)\n",
      "Exported lines 76200-76499 to steamspy_data.csv. Batch 73 time: 0:02:29 (avg: 0:02:32, remaining: 3:13:05)\n",
      "Exported lines 76500-76799 to steamspy_data.csv. Batch 74 time: 0:02:28 (avg: 0:02:32, remaining: 3:10:28)\n",
      "Exported lines 76800-77099 to steamspy_data.csv. Batch 75 time: 0:02:29 (avg: 0:02:32, remaining: 3:07:53)\n",
      "Exported lines 77100-77399 to steamspy_data.csv. Batch 76 time: 0:02:27 (avg: 0:02:32, remaining: 3:05:15)\n",
      "Exported lines 77400-77699 to steamspy_data.csv. Batch 77 time: 0:02:26 (avg: 0:02:32, remaining: 3:02:38)\n",
      "Exported lines 77700-77999 to steamspy_data.csv. Batch 78 time: 0:02:27 (avg: 0:02:32, remaining: 3:00:01)\n",
      "Exported lines 78000-78299 to steamspy_data.csv. Batch 79 time: 0:02:26 (avg: 0:02:32, remaining: 2:57:24)\n",
      "Exported lines 78300-78599 to steamspy_data.csv. Batch 80 time: 0:02:27 (avg: 0:02:32, remaining: 2:54:47)\n",
      "Exported lines 78600-78899 to steamspy_data.csv. Batch 81 time: 0:02:28 (avg: 0:02:32, remaining: 2:52:12)\n",
      "Exported lines 78900-79199 to steamspy_data.csv. Batch 82 time: 0:02:27 (avg: 0:02:32, remaining: 2:49:36)\n",
      "Exported lines 79200-79499 to steamspy_data.csv. Batch 83 time: 0:02:27 (avg: 0:02:32, remaining: 2:47:00)\n",
      "Exported lines 79500-79799 to steamspy_data.csv. Batch 84 time: 0:02:27 (avg: 0:02:32, remaining: 2:44:24)\n",
      "Exported lines 79800-80099 to steamspy_data.csv. Batch 85 time: 0:02:27 (avg: 0:02:32, remaining: 2:41:49)\n",
      "Exported lines 80100-80399 to steamspy_data.csv. Batch 86 time: 0:02:27 (avg: 0:02:32, remaining: 2:39:14)\n",
      "Exported lines 80400-80699 to steamspy_data.csv. Batch 87 time: 0:02:50 (avg: 0:02:32, remaining: 2:36:56)\n",
      "Exported lines 80700-80999 to steamspy_data.csv. Batch 88 time: 0:02:28 (avg: 0:02:32, remaining: 2:34:21)\n",
      "Exported lines 81000-81299 to steamspy_data.csv. Batch 89 time: 0:02:29 (avg: 0:02:32, remaining: 2:31:47)\n",
      "Exported lines 81300-81599 to steamspy_data.csv. Batch 90 time: 0:02:51 (avg: 0:02:32, remaining: 2:29:28)\n",
      "Exported lines 81600-81899 to steamspy_data.csv. Batch 91 time: 0:02:29 (avg: 0:02:32, remaining: 2:26:54)\n",
      "Error with 23281509\n",
      "Error with 23281600\n",
      "Error with 23281801\n",
      "Error with 23282402\n",
      "Exported lines 81900-82199 to steamspy_data.csv. Batch 92 time: 0:05:17 (avg: 0:02:34, remaining: 2:26:03)\n",
      "Exported lines 82200-82499 to steamspy_data.csv. Batch 93 time: 0:02:29 (avg: 0:02:34, remaining: 2:23:26)\n",
      "Exported lines 82500-82799 to steamspy_data.csv. Batch 94 time: 0:02:27 (avg: 0:02:34, remaining: 2:20:49)\n",
      "Exported lines 82800-83099 to steamspy_data.csv. Batch 95 time: 0:02:28 (avg: 0:02:34, remaining: 2:18:12)\n",
      "Exported lines 83100-83399 to steamspy_data.csv. Batch 96 time: 0:02:27 (avg: 0:02:33, remaining: 2:15:35)\n",
      "Exported lines 83400-83699 to steamspy_data.csv. Batch 97 time: 0:02:27 (avg: 0:02:33, remaining: 2:12:58)\n",
      "Exported lines 83700-83999 to steamspy_data.csv. Batch 98 time: 0:02:28 (avg: 0:02:33, remaining: 2:10:22)\n",
      "Exported lines 84000-84299 to steamspy_data.csv. Batch 99 time: 0:02:27 (avg: 0:02:33, remaining: 2:07:46)\n",
      "Exported lines 84300-84599 to steamspy_data.csv. Batch 100 time: 0:02:28 (avg: 0:02:33, remaining: 2:05:10)\n",
      "Exported lines 84600-84899 to steamspy_data.csv. Batch 101 time: 0:02:27 (avg: 0:02:33, remaining: 2:02:33)\n",
      "Exported lines 84900-85199 to steamspy_data.csv. Batch 102 time: 0:02:27 (avg: 0:02:33, remaining: 1:59:58)\n",
      "Exported lines 85200-85499 to steamspy_data.csv. Batch 103 time: 0:02:29 (avg: 0:02:33, remaining: 1:57:23)\n",
      "Exported lines 85500-85799 to steamspy_data.csv. Batch 104 time: 0:02:28 (avg: 0:02:33, remaining: 1:54:47)\n",
      "Exported lines 85800-86099 to steamspy_data.csv. Batch 105 time: 0:02:29 (avg: 0:02:33, remaining: 1:52:13)\n",
      "Exported lines 86100-86399 to steamspy_data.csv. Batch 106 time: 0:02:27 (avg: 0:02:33, remaining: 1:49:37)\n",
      "Exported lines 86400-86699 to steamspy_data.csv. Batch 107 time: 0:02:27 (avg: 0:02:33, remaining: 1:47:02)\n",
      "Exported lines 86700-86999 to steamspy_data.csv. Batch 108 time: 0:02:28 (avg: 0:02:33, remaining: 1:44:27)\n",
      "Exported lines 87000-87299 to steamspy_data.csv. Batch 109 time: 0:02:27 (avg: 0:02:33, remaining: 1:41:52)\n",
      "Exported lines 87300-87599 to steamspy_data.csv. Batch 110 time: 0:02:27 (avg: 0:02:33, remaining: 1:39:17)\n",
      "Exported lines 87600-87899 to steamspy_data.csv. Batch 111 time: 0:02:27 (avg: 0:02:33, remaining: 1:36:43)\n",
      "Exported lines 87900-88199 to steamspy_data.csv. Batch 112 time: 0:02:28 (avg: 0:02:33, remaining: 1:34:08)\n",
      "Exported lines 88200-88499 to steamspy_data.csv. Batch 113 time: 0:02:27 (avg: 0:02:33, remaining: 1:31:34)\n",
      "Exported lines 88500-88799 to steamspy_data.csv. Batch 114 time: 0:02:27 (avg: 0:02:33, remaining: 1:29:00)\n",
      "Exported lines 88800-89099 to steamspy_data.csv. Batch 115 time: 0:02:30 (avg: 0:02:33, remaining: 1:26:26)\n",
      "Exported lines 89100-89399 to steamspy_data.csv. Batch 116 time: 0:02:28 (avg: 0:02:33, remaining: 1:23:53)\n",
      "Exported lines 89400-89699 to steamspy_data.csv. Batch 117 time: 0:02:30 (avg: 0:02:32, remaining: 1:21:19)\n",
      "Exported lines 89700-89999 to steamspy_data.csv. Batch 118 time: 0:02:28 (avg: 0:02:32, remaining: 1:18:46)\n",
      "Exported lines 90000-90299 to steamspy_data.csv. Batch 119 time: 0:02:27 (avg: 0:02:32, remaining: 1:16:12)\n",
      "Exported lines 90300-90599 to steamspy_data.csv. Batch 120 time: 0:02:27 (avg: 0:02:32, remaining: 1:13:38)\n",
      "Exported lines 90600-90899 to steamspy_data.csv. Batch 121 time: 0:02:28 (avg: 0:02:32, remaining: 1:11:05)\n",
      "Exported lines 90900-91199 to steamspy_data.csv. Batch 122 time: 0:02:26 (avg: 0:02:32, remaining: 1:08:31)\n",
      "Exported lines 91200-91499 to steamspy_data.csv. Batch 123 time: 0:02:28 (avg: 0:02:32, remaining: 1:05:58)\n",
      "Exported lines 91500-91799 to steamspy_data.csv. Batch 124 time: 0:02:28 (avg: 0:02:32, remaining: 1:03:25)\n",
      "Exported lines 91800-92099 to steamspy_data.csv. Batch 125 time: 0:02:28 (avg: 0:02:32, remaining: 1:00:52)\n",
      "Exported lines 92100-92399 to steamspy_data.csv. Batch 126 time: 0:02:26 (avg: 0:02:32, remaining: 0:58:19)\n",
      "Exported lines 92400-92699 to steamspy_data.csv. Batch 127 time: 0:02:28 (avg: 0:02:32, remaining: 0:55:46)\n",
      "Exported lines 92700-92999 to steamspy_data.csv. Batch 128 time: 0:02:26 (avg: 0:02:32, remaining: 0:53:13)\n",
      "Exported lines 93000-93299 to steamspy_data.csv. Batch 129 time: 0:02:26 (avg: 0:02:32, remaining: 0:50:40)\n",
      "Exported lines 93300-93599 to steamspy_data.csv. Batch 130 time: 0:02:28 (avg: 0:02:32, remaining: 0:48:07)\n",
      "Exported lines 93600-93899 to steamspy_data.csv. Batch 131 time: 0:02:26 (avg: 0:02:32, remaining: 0:45:34)\n",
      "Exported lines 93900-94199 to steamspy_data.csv. Batch 132 time: 0:02:24 (avg: 0:02:32, remaining: 0:43:02)\n",
      "Exported lines 94200-94499 to steamspy_data.csv. Batch 133 time: 0:02:25 (avg: 0:02:32, remaining: 0:40:29)\n",
      "Exported lines 94500-94799 to steamspy_data.csv. Batch 134 time: 0:02:26 (avg: 0:02:32, remaining: 0:37:56)\n",
      "Exported lines 94800-95099 to steamspy_data.csv. Batch 135 time: 0:02:26 (avg: 0:02:32, remaining: 0:35:24)\n",
      "Exported lines 95100-95399 to steamspy_data.csv. Batch 136 time: 0:02:27 (avg: 0:02:32, remaining: 0:32:52)\n",
      "Exported lines 95400-95699 to steamspy_data.csv. Batch 137 time: 0:02:49 (avg: 0:02:32, remaining: 0:30:22)\n",
      "Exported lines 95700-95999 to steamspy_data.csv. Batch 138 time: 0:02:29 (avg: 0:02:32, remaining: 0:27:50)\n",
      "Exported lines 96000-96299 to steamspy_data.csv. Batch 139 time: 0:02:25 (avg: 0:02:32, remaining: 0:25:17)\n",
      "Exported lines 96300-96599 to steamspy_data.csv. Batch 140 time: 0:02:46 (avg: 0:02:32, remaining: 0:22:47)\n",
      "Exported lines 96600-96899 to steamspy_data.csv. Batch 141 time: 0:02:26 (avg: 0:02:32, remaining: 0:20:15)\n",
      "Error with 27493403\n",
      "Error with 27493604\n",
      "Error with 27493705\n",
      "Error with 27495006\n",
      "Exported lines 96900-97199 to steamspy_data.csv. Batch 142 time: 0:04:03 (avg: 0:02:32, remaining: 0:17:47)\n",
      "Exported lines 97200-97499 to steamspy_data.csv. Batch 143 time: 0:02:26 (avg: 0:02:32, remaining: 0:15:14)\n",
      "Exported lines 97500-97799 to steamspy_data.csv. Batch 144 time: 0:02:26 (avg: 0:02:32, remaining: 0:12:42)\n",
      "Exported lines 97800-98099 to steamspy_data.csv. Batch 145 time: 0:02:25 (avg: 0:02:32, remaining: 0:10:09)\n",
      "Exported lines 98100-98399 to steamspy_data.csv. Batch 146 time: 0:02:26 (avg: 0:02:32, remaining: 0:07:37)\n",
      "Exported lines 98400-98699 to steamspy_data.csv. Batch 147 time: 0:02:27 (avg: 0:02:32, remaining: 0:05:04)\n",
      "Exported lines 98700-98999 to steamspy_data.csv. Batch 148 time: 0:02:26 (avg: 0:02:32, remaining: 0:02:32)\n",
      "Exported lines 99000-99222 to steamspy_data.csv. Batch 149 time: 0:01:47 (avg: 0:02:32, remaining: 0:00:00)\n",
      "\n",
      "Processing batches complete. 44912 apps written\n"
     ]
    }
   ],
   "source": [
    "def parse_steamspy_request(appid):\n",
    "    \"\"\"Parser to handle SteamSpy API data.\"\"\"\n",
    "    url = \"https://steamspy.com/api.php\"\n",
    "    parameters = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "# set files and columns\n",
    "download_path = '../data/download'\n",
    "steamspy_data = 'steamspy_data.csv'\n",
    "steamspy_index = 'steamspy_index.txt'\n",
    "\n",
    "steamspy_columns = [\n",
    "    'appid', 'name', 'developer', 'publisher', 'score_rank', 'positive',\n",
    "    'negative', 'userscore', 'owners', 'average_forever', 'average_2weeks',\n",
    "    'median_forever', 'median_2weeks', 'price', 'initialprice', 'discount',\n",
    "    'languages', 'genre', 'ccu', 'tags'\n",
    "]\n",
    "\n",
    "#reset_index(download_path, steamspy_index)\n",
    "index = get_index(download_path, steamspy_index)\n",
    "\n",
    "# Wipe data file if index is 0\n",
    "prepare_data_file(download_path, steamspy_data, index, steamspy_columns)\n",
    "\n",
    "process_batches(\n",
    "    parser=parse_steamspy_request,\n",
    "    app_list=full_steam_ids[\"appid\"],\n",
    "    download_path=download_path, \n",
    "    data_filename=steamspy_data,\n",
    "    index_filename=steamspy_index,\n",
    "    columns=steamspy_columns,\n",
    "    begin=index,\n",
    "    end=len(full_steam_ids),\n",
    "    batchsize=300,\n",
    "    pause=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_spy_data = pd.read_csv('../data/download/steamspy_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99449 entries, 0 to 99448\n",
      "Data columns (total 20 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   appid            99449 non-null  int64  \n",
      " 1   name             99157 non-null  object \n",
      " 2   developer        76375 non-null  object \n",
      " 3   publisher        76355 non-null  object \n",
      " 4   score_rank       45 non-null     float64\n",
      " 5   positive         99449 non-null  int64  \n",
      " 6   negative         99449 non-null  int64  \n",
      " 7   userscore        99449 non-null  int64  \n",
      " 8   owners           99449 non-null  object \n",
      " 9   average_forever  99449 non-null  int64  \n",
      " 10  average_2weeks   99449 non-null  int64  \n",
      " 11  median_forever   99449 non-null  int64  \n",
      " 12  median_2weeks    99449 non-null  int64  \n",
      " 13  price            76568 non-null  float64\n",
      " 14  initialprice     76570 non-null  float64\n",
      " 15  discount         76570 non-null  float64\n",
      " 16  languages        76528 non-null  object \n",
      " 17  genre            76353 non-null  object \n",
      " 18  ccu              99449 non-null  int64  \n",
      " 19  tags             99449 non-null  object \n",
      "dtypes: float64(4), int64(9), object(7)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "steam_spy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_spy_data.duplicated(subset=\"appid\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steam Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_steamreviews_request(appid):\n",
    "    \"\"\"Parser to handle SteamSpy API data.\"\"\"\n",
    "    url = \"https://store.steampowered.com/appreviews/\" + str(appid)\n",
    "    parameters = {\"json\": 1, \"num_per_page\": \"0\", \"language\": \"all\", \"purchase_type\": \"all\"}\n",
    "    json_data = get_request(url, parameters)\n",
    "    json_data = json_data['query_summary']\n",
    "    json_data[\"appid\"]=appid\n",
    "    return json_data\n",
    "\n",
    "\n",
    "# set files and columns\n",
    "download_path = '../data/download'\n",
    "steamreviews_data = 'steamreviews_data.csv'\n",
    "steamreviews_index = 'steamreviews_index.txt'\n",
    "\n",
    "steamreviews_columns = [\n",
    "    'appid', 'review_score', 'review_score_desc', 'total_positive', 'total_negative', 'total_reviews'\n",
    "]\n",
    "\n",
    "reset_index(download_path, steamreviews_index)\n",
    "index = get_index(download_path, steamreviews_index)\n",
    "\n",
    "# Wipe data file if index is 0\n",
    "prepare_data_file(download_path, steamreviews_data, index, steamreviews_columns)\n",
    "\n",
    "full_steam_ids=pd.read_csv(\"../data/download/steam_app_data.csv\")\n",
    "\n",
    "process_batches(\n",
    "    parser=parse_steamreviews_request,\n",
    "    app_list=full_steam_ids[\"steam_appid\"],\n",
    "    download_path=download_path, \n",
    "    data_filename=steamreviews_data,\n",
    "    index_filename=steamreviews_index,\n",
    "    columns=steamreviews_columns,\n",
    "    begin=index,\n",
    "    end=len(full_steam_ids),\n",
    "    batchsize=300,\n",
    "    pause=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamreviews=pd.read_csv(\"../data/download/steamreviews_data.csv\", index_col=\"appid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamreviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamreviews[\"total_reviews\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamreviews[\"review_score_desc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamreviews[\"review_score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
